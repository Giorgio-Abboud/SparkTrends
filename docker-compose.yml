services:
  postgres:
    image: postgres:latest
    container_name: market-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    restart: always
    volumes:
    - pg_data_dev:/var/lib/postgresql/data
    - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
    - sparktrends_net
    healthcheck:
      test:
      - CMD
      - pg_isready
      - -h
      - localhost
      - -p
      - '5432'
      - -U
      - ${POSTGRES_USER}
      - -d
      - ${POSTGRES_DB}
      interval: 10s
      timeout: 5s
      retries: 5
    env_file: .env
    ports:
    - 5432:5432
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    env_file:
    - .env
    restart: unless-stopped
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      CLUSTER_ID: n3f038IOQDyaa7MzmFzAdw
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
    - kafka_data_dev:/var/lib/kafka/data
    networks:
    - sparktrends_net
    healthcheck:
      test:
      - CMD
      - sh
      - -c
      - nc -z localhost 9092
      interval: 10s
      timeout: 5s
      retries: 10
    ports:
    - 9092:9092
  spark-master:
    container_name: spark-master
    build:
      context: .
      dockerfile: Dockerfile.spark
    image: custom-spark:4.0.0
    restart: unless-stopped
    environment:
    - SPARK_MODE=master
    - SPARK_RPC_AUTHENTICATION_ENABLED=no
    - SPARK_RPC_ENCRYPTION_ENABLED=no
    - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
    - SPARK_SSL_ENABLED=no
    - SPARK_USER=spark
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8080
      interval: 5s
      timeout: 3s
      retries: 3
    volumes:
    - spark-logs:/opt/bitnami/spark/logs
    env_file:
    - .env
    ports:
    - 8080:8080
    - 7077:7077
    networks:
    - sparktrends_net
  spark-worker:
    container_name: spark-worker
    build:
      context: .
      dockerfile: Dockerfile.spark
    image: custom-spark:4.0.0
    restart: unless-stopped
    depends_on:
    - spark-master
    environment:
    - SPARK_MODE=worker
    - SPARK_MASTER_URL=spark://spark-master:7077
    - SPARK_WORKER_MEMORY=1G
    - SPARK_WORKER_CORES=1
    - SPARK_RPC_AUTHENTICATION_ENABLED=no
    - SPARK_RPC_ENCRYPTION_ENABLED=no
    - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
    - SPARK_SSL_ENABLED=no
    - SPARK_USER=spark
    env_file:
    - .env
    volumes:
    - spark-logs:/opt/bitnami/spark/logs
    networks:
    - sparktrends_net
  runner:
    container_name: runner
    build:
      context: .
      dockerfile: Dockerfile.runner
    restart: on-failure
    depends_on:
    - postgres
    - kafka
    - spark-master
    - spark-worker
    env_file:
    - .env
    volumes:
    - ./jars:/app/jars
    command:
    - spark-submit
    - --master
    - spark://spark-master:7077
    - --deploy-mode
    - client
    - /app/edge_runner.py
    - --mode
    - batch
    networks:
    - sparktrends_net
volumes:
  pg_data_dev: {}
  kafka_data_dev: {}
  spark-logs: {}
networks:
  sparktrends_net:
    driver: bridge
